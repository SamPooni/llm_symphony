<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Prompt Assembly & Prefill - Inference Stages 3-4</title>
  <script src="https://unpkg.com/react@18/umd/react.production.min.js"></script>
  <script src="https://unpkg.com/react-dom@18/umd/react-dom.production.min.js"></script>
  <script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>
  <script src="https://cdn.tailwindcss.com"></script>
  <style>
    * { margin: 0; padding: 0; box-sizing: border-box; }
    body { background: #000; min-height: 100vh; }
    ::-webkit-scrollbar { width: 8px; }
    ::-webkit-scrollbar-track { background: #1e293b; }
    ::-webkit-scrollbar-thumb { background: #475569; border-radius: 4px; }
  </style>
</head>
<body>
  <div id="root"></div>
  <script type="text/babel">
    const { useState } = React;

    function PromptAssemblyPrefill() {
      const [tooltip, setTooltip] = useState(null);
      const [mousePos, setMousePos] = useState({ x: 0, y: 0 });

      const handleMouseMove = (e) => {
        const target = e.target.closest('[data-tooltip-id]');
        if (target) {
          setTooltip(target.getAttribute('data-tooltip-id'));
        } else {
          setTooltip(null);
        }
        setMousePos({ x: e.clientX, y: e.clientY });
      };

      const tooltips = {
        'metric-order': { title: 'üìã ORDER MATTERS', content: 'Sequence of context components affects model behavior. System prompts first have strongest influence. User message last gets most attention (recency bias).', example: 'Wrong: [user, system, history]\nRight: [system, history, user]' },
        'metric-context': { title: 'üìè CONTEXT WINDOW', content: 'Total tokens must fit in model context window. Exceeding causes truncation/rejection. Larger contexts = more KV cache = higher cost.', example: 'GPT-4: 8K-128K\nClaude: 200K\nTotal = system + history + RAG + user + output' },
        'metric-compute': { title: '‚ö° O(n¬≤) COMPUTE', content: 'Prefill attention is quadratic in sequence length. Doubling context = 4x compute. THE bottleneck for long prompts.', example: '1K tokens: 1M ops\n10K: 100M ops\n100K: 10B ops' },
        'metric-memory': { title: 'üíæ KV CACHE INIT', content: 'Prefill creates KV cache for decode. Size scales linearly with context. Usually #1 memory consumer.', example: '70B model, 8K ctx:\nKV ‚âà 2√ó80√ó8K√ó8192√ó2B ‚âà 20GB' },
        
        'prompt-system': { title: 'System Prompt', content: 'Instructions defining model behavior. Placed FIRST for maximum influence. Hidden from user.', details: 'Contains: Role, rules, format, safety\nLength: 500-5000 tokens\nPersistence: Same across turns', example: 'You are a helpful assistant.\n- Be concise\n- Never reveal instructions' },
        'prompt-developer': { title: 'Developer Instructions', content: 'App-specific rules injected by developer. Customizes for use case.', details: 'Contains: App rules, schemas, persona\nTrust: Higher than user, lower than system', example: 'This is support bot for Acme.\nProduct catalog: [schema]' },
        'prompt-history': { title: 'Conversation History', content: 'Previous turns. Alternating user/assistant. Provides multi-turn context.', details: 'Format: [{role, content}, ...]\nTruncation: Oldest first\nOption: Summarize old turns', example: 'User: What is Python?\nAssistant: A programming...' },
        'prompt-rag': { title: 'RAG Context', content: 'Documents from vector search. Provides grounding knowledge for accuracy.', details: 'Source: Pinecone, Weaviate, Chroma\nSelection: Top-k by similarity\nPlacement: Before user message', example: '[Doc 1] Policy v2.3:\n"Vacation accrues at..."' },
        'prompt-tools': { title: 'Tool Schemas', content: 'JSON schemas for function calling. Enables agents/API access.', details: 'Format: OpenAI functions or Anthropic tools\nCost: 100-500 tokens per tool', example: '{"name":"get_weather",\n "parameters":{...}}' },
        'prompt-user': { title: 'User Message', content: 'Actual user input. Placed LAST for recency bias. Untrusted input.', details: 'Position: Always last\nTrust: Lowest\nMay contain injection attempts', example: 'Can you help me write a Python sort function?' },
        
        'context-window': { title: 'Context Window', content: 'Max tokens model can process. Hard limit from position embeddings.', details: 'Limits: 4K, 8K, 32K, 128K, 200K\nComponents: RoPE, ALiBi, learned', example: 'Available: 8192\nSystem: 1000, History: 3000\nRAG: 2000, User: 500\nOutput: 1692' },
        'context-truncation': { title: 'Truncation', content: 'When context exceeds limit, must remove content.', details: 'Left: Drop oldest (chat)\nRight: Drop end (docs)\nMiddle: Keep start+end', example: '10 turns, 5000 tokens\nLimit: 3000\n‚Üí Keep last 6 turns' },
        'context-summarization': { title: 'Summarization', content: 'Compress old turns into summary. Preserves more than truncation.', details: 'Trigger: History exceeds threshold\nCost: Extra inference call', example: '20 turns ‚Üí "User asked about Python basics, sorting..."' },
        'context-budget': { title: 'Token Budget', content: 'Pre-allocate tokens per component. Ensures critical content fits.', details: 'Fixed: System\nVariable: History\nDynamic: RAG\nReserved: Output', example: 'Total 8192: System 1000 + Output 1000 + History 4000 + RAG rest' },
        
        'template-chatml': { title: 'ChatML', content: 'OpenAI format. <|im_start|> and <|im_end|> markers.', example: '<|im_start|>system\nHelpful assistant<|im_end|>\n<|im_start|>user\nHello!<|im_end|>' },
        'template-llama': { title: 'Llama', content: 'Meta format. [INST] markers, <<SYS>> for system.', example: '[INST] <<SYS>>\nHelpful.\n<</SYS>>\nHello! [/INST]' },
        'template-claude': { title: 'Claude', content: 'Anthropic Human/Assistant format.', example: 'Human: Hello!\n\nAssistant: Hi there!' },
        
        'prefill-embedding': { title: 'Token Embedding', content: 'Look up dense vectors for each token ID from embedding table.', details: 'Shape: [batch, seq] ‚Üí [batch, seq, hidden]\nSize: vocab √ó hidden √ó 2 bytes', example: 'input_ids [15496, 995]\n‚Üí [4096-dim vectors]' },
        'prefill-position': { title: 'Position Encoding', content: 'Add position info. RoPE most common now.', details: 'Types: Sinusoidal, Learned, RoPE, ALiBi\nRoPE: Rotate Q,K by position angle', example: 'Pos 0: angle 0\nPos 1: angle Œ∏' },
        'prefill-attention': { title: 'Self-Attention', content: 'THE expensive op. Every token attends to every other. O(n¬≤).', details: 'Compute: Q√óK^T ‚Üí softmax ‚Üí √óV\nShape: [batch, heads, seq, seq]\nOptimization: Flash Attention', example: '8192 seq, 32 heads\n= 32√ó8192√ó8192\n= 2.1B elements/layer' },
        'prefill-qkv': { title: 'QKV Projections', content: 'Project to Query, Key, Value. Three large matmuls per layer.', details: 'Projections: W_Q, W_K, W_V\nGQA: Shares K,V across heads\nMQA: Single K,V for all heads', example: 'Hidden 4096, 32 heads\nW_Q: 4096√ó4096' },
        'prefill-ffn': { title: 'FFN/MLP', content: 'Feed-forward after attention. 4√ó expansion. ~2/3 of params.', details: 'Architecture: Linear‚ÜíGeLU‚ÜíLinear\nExpansion: hidden√ó4', example: 'Hidden 4096 ‚Üí 16384 ‚Üí 4096\n268M params/layer' },
        'prefill-layernorm': { title: 'LayerNorm', content: 'Normalize for stability. RMSNorm common variant.', details: 'Types: LayerNorm, RMSNorm\nPosition: Pre-norm (before) typical', example: 'x = [0.5, 1.2, -0.3]\nRMS = 0.76\nOut = x/RMS' },
        
        'kv-creation': { title: 'KV Cache Creation', content: 'Store K,V for every layer at every position during prefill.', details: 'Stored: K,V per layer\nShape: [batch, kv_heads, seq, head_dim]\nUsed: Every decode step', example: '80 layers, 8K seq\n= 2.5GB per sequence' },
        'kv-memory': { title: 'KV Memory', content: '#1 memory consumer. Limits batch size and context.', details: 'Formula: 2√ólayers√óheads√óseq√ódim√ódtype\nScaling: Linear with seq\nQuantization: FP8 halves size', example: '70B, 8K ctx = 2.5GB/seq\nBatch of 8 = 20GB!' },
        'kv-paged': { title: 'PagedAttention', content: 'Virtual memory for KV. No fragmentation, higher batches.', details: 'Concept: KV as pages (like OS)\nBenefit: No pre-allocation waste\nSharing: Prefix cache reuse', example: 'Traditional: 50-90% waste\nPaged: ~100% utilization' },
        
        'opt-flash': { title: 'Flash Attention', content: 'Never materializes full N√óN matrix. Huge memory savings.', details: 'Trick: Compute in tiles in SRAM\nMemory: O(N) not O(N¬≤)\nSpeed: 2-4√ó faster', example: '8192√ó8192: 268MB‚Üí512KB\nNo quality loss!' },
        'opt-fusion': { title: 'Kernel Fusion', content: 'Combine ops into one kernel. Reduces memory bandwidth.', details: 'Examples: QKV‚Üí1, attention‚Üí1, LN+bias‚Üí1\nBenefit: Fewer memory trips', example: 'Unfused: Load‚ÜíOp‚ÜíStore√ó3\nFused: Load‚ÜíOps‚ÜíStore' },
        'opt-tensor': { title: 'Tensor Cores', content: 'Specialized GPU hardware for matmul. 8-16√ó speedup.', details: 'Supported: FP16, BF16, INT8, FP8\nRequirement: Shapes √ó8/16 aligned', example: 'CUDA: 19.5 TFLOPS\nTensor: 312 TFLOPS (FP16)' },
        
        'output-hidden': { title: 'Hidden States', content: 'Final layer output. Only last position goes to logits.', details: 'Shape: [batch, seq, hidden]\nUsed: Last pos ‚Üí output proj', example: '[1, 2, 4096] ‚Üí hidden[:,-1,:] ‚Üí logits' },
        'output-logits': { title: 'Initial Logits', content: 'Project to vocab size. First generated token logits.', details: 'Projection: hidden‚Üívocab\nNext: Softmax ‚Üí sample', example: '[1,4096]√ó[4096,100K]‚Üí[1,100K]' },
        
        'complexity-compute': { title: 'Compute Complexity', content: 'Prefill is compute-bound. O(n¬≤) attention dominates.', details: 'Attention: O(n¬≤√ód)\nFFN: O(n√ód¬≤)\nTotal: O(L√ón¬≤√ód)', example: 'n>d: attention dominates\nn<d: FFN dominates' },
        'complexity-memory': { title: 'Memory Complexity', content: 'Peak: attention + KV + activations. Flash reduces attention.', details: 'Attention: O(n¬≤)‚ÜíO(n) Flash\nKV: O(n√ód√óL)\nWeights: O(d¬≤√óL)', example: 'Weights: 140GB\nKV: 2.5GB/8K\nActivations: ~1GB' },
      };

      const Tooltip = () => {
        if (!tooltip || !tooltips[tooltip]) return null;
        const t = tooltips[tooltip];
        
        return (
          <div className="fixed z-50 w-[380px] p-4 bg-slate-900 border-2 border-white/20 rounded-xl shadow-2xl" style={{ right: 20, bottom: 20 }}>
            <div className="text-lg font-black text-white mb-2">{t.title}</div>
            <p className="text-slate-300 text-sm leading-relaxed mb-2">{t.content}</p>
            {t.details && <div className="bg-black/50 rounded-lg p-2 mb-2"><div className="text-xs text-slate-500 font-bold mb-1">DETAILS</div><pre className="text-xs text-cyan-300 font-mono whitespace-pre-wrap">{t.details}</pre></div>}
            {t.example && <div className="bg-black/50 rounded-lg p-2"><div className="text-xs text-slate-500 font-bold mb-1">EXAMPLE</div><pre className="text-xs text-green-300 font-mono whitespace-pre-wrap">{t.example}</pre></div>}
          </div>
        );
      };

      const H = ({ id, children, className = '' }) => (
        <div className={`cursor-help transition-all hover:scale-[1.02] ${className}`} data-tooltip-id={id} >{children}</div>
      );

      return (
        <div className="min-h-screen bg-black p-6" onMouseMove={handleMouseMove}>
          <Tooltip />
          <div className="relative max-w-7xl mx-auto">
            {/* Header */}
            <header className="text-center mb-10">
              <div className="inline-flex items-center gap-2 px-5 py-2 rounded-full bg-indigo-500/20 border-2 border-indigo-400 mb-4">
                <span className="text-indigo-300 font-black text-lg">STAGES 3-4</span>
                <span className="text-white">‚Ä¢</span>
                <span className="text-indigo-200 font-medium">CPU ‚Üí GPU Transition</span>
              </div>
              <h1 className="text-5xl font-black mb-4 text-transparent bg-clip-text bg-gradient-to-r from-indigo-400 via-cyan-400 to-emerald-400">Prompt Assembly & Prefill</h1>
              <p className="text-xl text-slate-200 max-w-3xl mx-auto"><span className="text-indigo-300 font-bold">Context ‚Üí KV Cache</span> ‚Äî order matters, O(n¬≤) hurts. <span className="text-cyan-300">üñ±Ô∏è Hover for details.</span></p>
            </header>

            {/* Metrics */}
            <div className="grid grid-cols-4 gap-4 mb-10">
              <H id="metric-order"><div className="p-5 rounded-xl bg-indigo-600 border-2 border-indigo-400"><div className="flex items-center gap-2 mb-2"><span className="text-2xl">üìã</span><span className="text-sm font-black text-white/90">ORDER</span></div><div className="text-3xl font-black text-indigo-100">MATTERS</div><div className="text-sm text-white/80">Sequence affects behavior</div></div></H>
              <H id="metric-context"><div className="p-5 rounded-xl bg-cyan-600 border-2 border-cyan-400"><div className="flex items-center gap-2 mb-2"><span className="text-2xl">üìè</span><span className="text-sm font-black text-white/90">CONTEXT</span></div><div className="text-3xl font-black text-cyan-100">8K-200K</div><div className="text-sm text-white/80">Window must fit all</div></div></H>
              <H id="metric-compute"><div className="p-5 rounded-xl bg-red-600 border-2 border-red-400"><div className="flex items-center gap-2 mb-2"><span className="text-2xl">‚ö°</span><span className="text-sm font-black text-white/90">COMPUTE</span></div><div className="text-3xl font-black text-red-100">O(n¬≤)</div><div className="text-sm text-white/80">Attention is quadratic</div></div></H>
              <H id="metric-memory"><div className="p-5 rounded-xl bg-emerald-600 border-2 border-emerald-400"><div className="flex items-center gap-2 mb-2"><span className="text-2xl">üíæ</span><span className="text-sm font-black text-white/90">KV CACHE</span></div><div className="text-3xl font-black text-emerald-100">#1 MEM</div><div className="text-sm text-white/80">Biggest memory user</div></div></H>
            </div>

            {/* Section 3: Prompt Assembly */}
            <section className="mb-8">
              <div className="flex items-center gap-4 mb-6">
                <div className="w-14 h-14 rounded-xl bg-indigo-500 flex items-center justify-center text-white text-2xl font-black shadow-lg shadow-indigo-500/50">3</div>
                <div><h2 className="text-3xl font-black text-indigo-300">3.0 PROMPT ASSEMBLY</h2><p className="text-indigo-200/80">Order matters ‚Äî constructing the context</p></div>
              </div>

              <div className="bg-gradient-to-br from-indigo-950 to-violet-950 border-2 border-indigo-400 rounded-xl p-6">
                <div className="text-indigo-300 font-black text-lg mb-4">üì¶ CONTEXT COMPONENTS (IN ORDER)</div>
                <div className="space-y-3 mb-6">
                  {[
                    { id: 'prompt-system', n: 1, title: 'System Prompt', desc: 'Role, rules, safety', tokens: '~1000', tag: 'HIDDEN', color: 'indigo' },
                    { id: 'prompt-developer', n: 2, title: 'Developer Instructions', desc: 'App-specific rules', tokens: '~500', tag: 'HIDDEN', color: 'violet' },
                    { id: 'prompt-history', n: 3, title: 'Conversation History', desc: 'Previous turns', tokens: 'Variable', tag: 'TRUNCATABLE', color: 'blue' },
                    { id: 'prompt-rag', n: 4, title: 'RAG Context', desc: 'Retrieved documents', tokens: '~2000', tag: 'DYNAMIC', color: 'cyan' },
                    { id: 'prompt-tools', n: 5, title: 'Tool Schemas', desc: 'Function definitions', tokens: '~500', tag: 'OPTIONAL', color: 'teal' },
                    { id: 'prompt-user', n: 6, title: 'User Message', desc: 'Current input (LAST)', tokens: 'Variable', tag: 'UNTRUSTED', color: 'green' },
                  ].map(item => (
                    <H key={item.id} id={item.id}>
                      <div className={`flex items-center gap-4 bg-black/40 border-2 border-${item.color}-400 rounded-xl p-4`}>
                        <div className={`w-12 h-12 rounded-xl bg-${item.color}-500 flex items-center justify-center text-white text-xl font-black`}>{item.n}</div>
                        <div className="flex-1"><div className="text-white font-bold">{item.title}</div><div className={`text-${item.color}-200 text-sm`}>{item.desc}</div></div>
                        <div className={`text-${item.color}-400 font-mono text-sm`}>{item.tokens}</div>
                        <div className={`px-3 py-1 bg-${item.color}-500/30 rounded text-${item.color}-200 text-xs font-bold`}>{item.tag}</div>
                      </div>
                    </H>
                  ))}
                </div>

                <div className="text-amber-300 font-black text-lg mb-4">‚öôÔ∏è CONTEXT MANAGEMENT</div>
                <div className="grid grid-cols-4 gap-4 mb-6">
                  {[
                    { id: 'context-window', icon: 'üìê', title: 'Window Size', desc: '8K ‚Üí 200K' },
                    { id: 'context-truncation', icon: '‚úÇÔ∏è', title: 'Truncation', desc: 'Left/Right/Middle' },
                    { id: 'context-summarization', icon: 'üìù', title: 'Summarization', desc: 'Compress history' },
                    { id: 'context-budget', icon: 'üí∞', title: 'Token Budget', desc: 'Allocate per part' },
                  ].map(item => (
                    <H key={item.id} id={item.id}>
                      <div className="bg-black/40 border-2 border-amber-400 rounded-xl p-4 text-center">
                        <div className="text-3xl mb-2">{item.icon}</div>
                        <div className="text-white font-bold">{item.title}</div>
                        <div className="text-amber-200 text-xs mt-1">{item.desc}</div>
                      </div>
                    </H>
                  ))}
                </div>

                <div className="text-pink-300 font-black text-lg mb-4">üè∑Ô∏è CHAT TEMPLATES</div>
                <div className="grid grid-cols-3 gap-4">
                  <H id="template-chatml"><div className="bg-black/40 border-2 border-pink-400 rounded-xl p-4"><div className="text-pink-300 font-bold mb-2">ChatML (OpenAI)</div><div className="font-mono text-xs text-slate-300 bg-black/50 rounded p-2">&lt;|im_start|&gt;system<br/>...<br/>&lt;|im_end|&gt;</div></div></H>
                  <H id="template-llama"><div className="bg-black/40 border-2 border-pink-400 rounded-xl p-4"><div className="text-pink-300 font-bold mb-2">Llama (Meta)</div><div className="font-mono text-xs text-slate-300 bg-black/50 rounded p-2">[INST] &lt;&lt;SYS&gt;&gt;<br/>...<br/>&lt;&lt;/SYS&gt;&gt; [/INST]</div></div></H>
                  <H id="template-claude"><div className="bg-black/40 border-2 border-pink-400 rounded-xl p-4"><div className="text-pink-300 font-bold mb-2">Claude (Anthropic)</div><div className="font-mono text-xs text-slate-300 bg-black/50 rounded p-2">Human: ...<br/><br/>Assistant: ...</div></div></H>
                </div>
              </div>
            </section>

            {/* Arrow */}
            <div className="flex justify-center my-6">
              <div className="flex flex-col items-center">
                <div className="w-1 h-8 bg-gradient-to-b from-indigo-400 to-cyan-400 rounded-full" />
                <div className="px-4 py-2 bg-cyan-500/20 border border-cyan-400 rounded-full text-cyan-300 text-sm font-bold">TOKENS ‚Üí GPU</div>
                <div className="w-1 h-8 bg-gradient-to-b from-cyan-400 to-emerald-400 rounded-full" />
              </div>
            </div>

            {/* Section 4: Prefill */}
            <section className="mb-8">
              <div className="flex items-center gap-4 mb-6">
                <div className="w-14 h-14 rounded-xl bg-cyan-500 flex items-center justify-center text-white text-2xl font-black shadow-lg shadow-cyan-500/50">4</div>
                <div><h2 className="text-3xl font-black text-cyan-300">4.0 PREFILL (Context Encoding)</h2><p className="text-cyan-200/80">Full attention over all tokens ‚Äî O(n¬≤) compute</p></div>
              </div>

              <div className="bg-gradient-to-br from-cyan-950 to-teal-950 border-2 border-cyan-400 rounded-xl p-6">
                {/* Prefill Pipeline */}
                <div className="text-cyan-300 font-black text-lg mb-4">‚ö° PREFILL PIPELINE</div>
                <div className="flex items-center gap-2 mb-6 overflow-x-auto pb-2">
                  {[
                    { id: 'prefill-embedding', title: 'Embed', desc: 'Lookup vectors' },
                    { id: 'prefill-position', title: 'Position', desc: 'Add RoPE' },
                    { id: 'prefill-layernorm', title: 'LayerNorm', desc: 'Normalize' },
                    { id: 'prefill-qkv', title: 'QKV Proj', desc: 'Q, K, V matrices' },
                    { id: 'prefill-attention', title: 'Attention', desc: 'O(n¬≤) EXPENSIVE' },
                    { id: 'prefill-ffn', title: 'FFN/MLP', desc: '4√ó expansion' },
                  ].map((item, i) => (
                    <React.Fragment key={item.id}>
                      <H id={item.id}>
                        <div className={`${item.id === 'prefill-attention' ? 'bg-red-600 border-red-400' : 'bg-cyan-600 border-cyan-400'} border-2 rounded-xl p-3 min-w-[100px] text-center`}>
                          <div className="text-white font-bold text-sm">{item.title}</div>
                          <div className={`${item.id === 'prefill-attention' ? 'text-red-200' : 'text-cyan-200'} text-xs`}>{item.desc}</div>
                        </div>
                      </H>
                      {i < 5 && <div className="text-cyan-400 text-xl">‚Üí</div>}
                    </React.Fragment>
                  ))}
                  <div className="text-cyan-400 text-xl">‚Üí</div>
                  <div className="px-3 py-1 bg-amber-500/30 border border-amber-400 rounded-full text-amber-300 text-xs font-bold">√ó80 LAYERS</div>
                </div>

                {/* KV Cache */}
                <div className="text-emerald-300 font-black text-lg mb-4">üíæ KV CACHE</div>
                <div className="grid grid-cols-3 gap-4 mb-6">
                  <H id="kv-creation"><div className="bg-black/40 border-2 border-emerald-400 rounded-xl p-4"><div className="text-2xl mb-2">üì¶</div><div className="text-white font-bold">Cache Creation</div><div className="text-emerald-200 text-xs">Store K,V per layer per position</div></div></H>
                  <H id="kv-memory"><div className="bg-black/40 border-2 border-emerald-400 rounded-xl p-4"><div className="text-2xl mb-2">üß†</div><div className="text-white font-bold">Memory Usage</div><div className="text-emerald-200 text-xs">#1 consumer: 2-20GB per seq</div></div></H>
                  <H id="kv-paged"><div className="bg-black/40 border-2 border-emerald-400 rounded-xl p-4"><div className="text-2xl mb-2">üìÑ</div><div className="text-white font-bold">PagedAttention</div><div className="text-emerald-200 text-xs">vLLM: virtual memory for KV</div></div></H>
                </div>

                {/* Optimizations */}
                <div className="text-purple-300 font-black text-lg mb-4">üöÄ OPTIMIZATIONS</div>
                <div className="grid grid-cols-3 gap-4 mb-6">
                  <H id="opt-flash"><div className="bg-black/40 border-2 border-purple-400 rounded-xl p-4"><div className="text-2xl mb-2">‚ö°</div><div className="text-white font-bold">Flash Attention</div><div className="text-purple-200 text-xs">O(n¬≤)‚ÜíO(n) memory, 2-4√ó faster</div></div></H>
                  <H id="opt-fusion"><div className="bg-black/40 border-2 border-purple-400 rounded-xl p-4"><div className="text-2xl mb-2">üîó</div><div className="text-white font-bold">Kernel Fusion</div><div className="text-purple-200 text-xs">Combine ops, reduce memory BW</div></div></H>
                  <H id="opt-tensor"><div className="bg-black/40 border-2 border-purple-400 rounded-xl p-4"><div className="text-2xl mb-2">üéØ</div><div className="text-white font-bold">Tensor Cores</div><div className="text-purple-200 text-xs">8-16√ó speedup for matmul</div></div></H>
                </div>

                {/* Output */}
                <div className="text-green-300 font-black text-lg mb-4">üì§ PREFILL OUTPUT</div>
                <div className="grid grid-cols-2 gap-4">
                  <H id="output-hidden"><div className="bg-black/40 border-2 border-green-400 rounded-xl p-4"><div className="text-green-300 font-bold mb-2">Hidden States</div><div className="text-slate-300 text-sm">Final layer output [batch, seq, hidden]</div><div className="text-green-200 text-xs mt-2">Last position ‚Üí logits projection</div></div></H>
                  <H id="output-logits"><div className="bg-black/40 border-2 border-green-400 rounded-xl p-4"><div className="text-green-300 font-bold mb-2">Initial Logits</div><div className="text-slate-300 text-sm">Project to vocab: [batch, vocab_size]</div><div className="text-green-200 text-xs mt-2">Ready for sampling first token</div></div></H>
                </div>
              </div>
            </section>

            {/* Complexity Summary */}
            <div className="grid grid-cols-2 gap-4 mb-8">
              <H id="complexity-compute"><div className="bg-slate-900 border-2 border-red-500 rounded-xl p-5"><div className="flex items-center gap-3"><span className="text-3xl">‚ö°</span><div><div className="text-red-300 font-black">COMPUTE: O(n¬≤)</div><div className="text-slate-400 text-sm">Attention dominates for long sequences</div></div></div></div></H>
              <H id="complexity-memory"><div className="bg-slate-900 border-2 border-emerald-500 rounded-xl p-5"><div className="flex items-center gap-3"><span className="text-3xl">üíæ</span><div><div className="text-emerald-300 font-black">MEMORY: KV CACHE</div><div className="text-slate-400 text-sm">Flash Attention: O(n¬≤)‚ÜíO(n) for attention</div></div></div></div></H>
            </div>

            {/* Output */}
            <div className="bg-gradient-to-r from-green-600 to-emerald-600 border-2 border-green-400 rounded-xl p-6 shadow-lg shadow-green-500/30">
              <div className="flex items-center justify-between flex-wrap gap-4">
                <div className="flex items-center gap-4"><span className="text-5xl">‚úÖ</span><div><div className="text-2xl font-black text-white">PREFILL COMPLETE</div><div className="text-green-200 font-medium">KV Cache ready + First token logits</div></div></div>
                <div className="text-right"><div className="text-green-200 font-semibold">NEXT STAGE ‚Üí</div><div className="text-white font-black text-lg">Decode Loop (Autoregressive)</div></div>
              </div>
            </div>

            {/* Footer */}
            <footer className="mt-12 text-center text-slate-400 text-sm border-t border-slate-800 pt-6">
              <p className="font-semibold">Prompt Assembly & Prefill ‚Ä¢ Stages 3-4 of Inference Lifecycle</p>
              <p className="text-cyan-400 font-bold mt-1">CONTEXT ‚Üí KV CACHE: THE EXPENSIVE PART</p>
            </footer>
          </div>
        </div>
      );
    }

    const root = ReactDOM.createRoot(document.getElementById('root'));
    root.render(<PromptAssemblyPrefill />);
  </script>
</body>
</html>
