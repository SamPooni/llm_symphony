<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>Long Context - 100K+ Token Handling</title>
  <script src="https://unpkg.com/react@18/umd/react.production.min.js"></script>
  <script src="https://unpkg.com/react-dom@18/umd/react-dom.production.min.js"></script>
  <script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>
  <script src="https://cdn.tailwindcss.com"></script>
</head>
<body style="margin:0;background:#000">
  <div id="root"></div>
  <script type="text/babel">
    function App() {
      const [hover, setHover] = React.useState(null);
      
      const tips = {
        'context': 'Context window = how much text model can see at once. GPT-4: 128K. Claude: 200K. Gemini: 1M+. Bigger enables new use cases.',
        'lost': 'Lost in the middle. Models struggle with info in middle of long context. Beginning and end attended well. Middle gets lost.',
        'rope': 'RoPE: Rotary Position Embedding. Encodes position via rotation. Can extrapolate beyond training length. Foundation of long context.',
        'yarn': 'YaRN: Yet another RoPE extension. Interpolates + extrapolates. Better than naive RoPE scaling. Open source technique.',
        'alibi': 'ALiBi: Attention with Linear Biases. No position embeddings. Bias attention by distance. Trains short, infers long.',
        'sliding': 'Sliding window attention. Only attend to local context. Mistral uses 4K window. Memory efficient but loses global.',
        'ring': 'Ring attention. Distribute sequence across devices. Each chunk attends locally, pass KV around ring. Enables massive context.',
        'chunk': 'Chunking strategy. Break document into chunks. Process separately or with overlap. Reassemble results. Simple scaling.',
        'hier': 'Hierarchical. Summarize chunks first. Attend to summaries. Recursive compression. Handles any length.',
        'rag': 'RAG vs long context. Retrieve relevant chunks vs stuff everything in. RAG cheaper, long context more complete. Tradeoffs.',
        'needle': 'Needle in haystack test. Hide fact in long context. Can model find it? Tests retrieval ability. Benchmark for long context.',
        'cost': 'Long context is expensive. 100K tokens = $$. Prefill latency high. Use strategically. RAG often cheaper.',
        'flash': 'Flash Attention. Memory-efficient attention. Enables longer context without OOM. Essential for 100K+. Must-have.',
        'gemini': 'Gemini 1M+ context. Largest commercial. Full codebase, long video. New capabilities. But expensive.'
      };

      const Card = ({id, bg, title, sub}) => (
        <div 
          className={`p-4 rounded-xl border-2 ${bg} cursor-pointer hover:scale-105 transition-transform relative`}
          onMouseEnter={() => setHover(id)}
          onMouseLeave={() => setHover(null)}
        >
          <div className="font-bold">{title}</div>
          <div className="text-sm opacity-60">{sub}</div>
          {hover === id && (
            <div className="absolute left-0 top-full mt-2 z-50 w-72 p-3 bg-slate-800 border border-cyan-500 rounded-lg text-sm text-white shadow-xl">
              {tips[id]}
            </div>
          )}
        </div>
      );

      return (
        <div className="min-h-screen bg-black text-white p-8">
          <div className="max-w-5xl mx-auto">
            <div className="text-center mb-8">
              <div className="inline-block px-4 py-1 bg-indigo-900/50 border border-indigo-500 rounded-full mb-4">
                <span className="text-indigo-300 font-bold text-sm">CONTEXT LENGTH</span>
              </div>
              <h1 className="text-4xl font-black mb-2 text-transparent bg-clip-text bg-gradient-to-r from-indigo-400 to-violet-500">
                Long Context Techniques
              </h1>
              <p className="text-slate-400">Handling 100K+ tokens. Hover for details.</p>
            </div>

            {/* Basics */}
            <div className="mb-8">
              <h2 className="text-lg font-bold mb-3 text-indigo-300">1. Basics</h2>
              <div className="grid grid-cols-3 gap-3">
                <Card id="context" bg="bg-indigo-900/50 border-indigo-500 text-indigo-200" title="Context Window" sub="128K to 1M+ tokens"/>
                <Card id="lost" bg="bg-indigo-900/50 border-indigo-500 text-indigo-200" title="Lost in Middle" sub="Attention challenge"/>
                <Card id="flash" bg="bg-indigo-900/50 border-indigo-500 text-indigo-200" title="Flash Attention" sub="Memory efficient"/>
              </div>
            </div>

            {/* Position Encoding */}
            <div className="mb-8">
              <h2 className="text-lg font-bold mb-3 text-blue-300">2. Position Encoding</h2>
              <div className="grid grid-cols-3 gap-3">
                <Card id="rope" bg="bg-blue-900/50 border-blue-500 text-blue-200" title="RoPE" sub="Rotary embeddings"/>
                <Card id="yarn" bg="bg-blue-900/50 border-blue-500 text-blue-200" title="YaRN" sub="RoPE extension"/>
                <Card id="alibi" bg="bg-blue-900/50 border-blue-500 text-blue-200" title="ALiBi" sub="Linear bias"/>
              </div>
            </div>

            {/* Attention Patterns */}
            <div className="mb-8">
              <h2 className="text-lg font-bold mb-3 text-green-300">3. Attention Patterns</h2>
              <div className="grid grid-cols-2 gap-3">
                <Card id="sliding" bg="bg-green-900/50 border-green-500 text-green-200" title="Sliding Window" sub="Local attention only"/>
                <Card id="ring" bg="bg-green-900/50 border-green-500 text-green-200" title="Ring Attention" sub="Distributed sequence"/>
              </div>
            </div>

            {/* Strategies */}
            <div className="mb-8">
              <h2 className="text-lg font-bold mb-3 text-orange-300">4. Strategies</h2>
              <div className="grid grid-cols-3 gap-3">
                <Card id="chunk" bg="bg-orange-900/50 border-orange-500 text-orange-200" title="Chunking" sub="Divide and process"/>
                <Card id="hier" bg="bg-orange-900/50 border-orange-500 text-orange-200" title="Hierarchical" sub="Recursive summary"/>
                <Card id="rag" bg="bg-orange-900/50 border-orange-500 text-orange-200" title="RAG vs Long" sub="Retrieve vs stuff"/>
              </div>
            </div>

            {/* Evaluation */}
            <div className="mb-8">
              <h2 className="text-lg font-bold mb-3 text-purple-300">5. Evaluation & Cost</h2>
              <div className="grid grid-cols-3 gap-3">
                <Card id="needle" bg="bg-purple-900/50 border-purple-500 text-purple-200" title="Needle Test" sub="Find hidden fact"/>
                <Card id="cost" bg="bg-purple-900/50 border-purple-500 text-purple-200" title="Cost" sub="Long = expensive"/>
                <Card id="gemini" bg="bg-purple-900/50 border-purple-500 text-purple-200" title="Gemini 1M" sub="Largest context"/>
              </div>
            </div>

            {/* Summary */}
            <div className="bg-slate-900/50 border border-indigo-500/30 rounded-xl p-6 text-center">
              <div className="text-xl font-bold text-white mb-2">Long Context Summary</div>
              <p className="text-slate-400 text-sm mb-4">
                RoPE/YaRN for position, Flash Attention for memory, RAG for cost. Beware lost-in-middle.
              </p>
              <div className="flex justify-center gap-3 flex-wrap">
                <span className="px-3 py-1 bg-blue-900/50 rounded text-blue-300 text-sm">RoPE</span>
                <span className="px-3 py-1 bg-green-900/50 rounded text-green-300 text-sm">Flash Attn</span>
                <span className="px-3 py-1 bg-orange-900/50 rounded text-orange-300 text-sm">Chunking</span>
                <span className="px-3 py-1 bg-purple-900/50 rounded text-purple-300 text-sm">Needle Test</span>
              </div>
            </div>
          </div>
        </div>
      );
    }
    ReactDOM.createRoot(document.getElementById('root')).render(<App />);
  </script>
</body>
</html>
